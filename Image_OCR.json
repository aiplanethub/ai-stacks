{"id":"d42d109e-2cf4-4280-84d2-2dd82a2456ff","data":{"nodes":[{"width":384,"height":547,"id":"AzureAIDocumentIntelligenceLoader-VUrhj","type":"genericNode","position":{"x":249,"y":202.265625},"data":{"type":"AzureAIDocumentIntelligenceLoader","node":{"template":{"code":{"dynamic":true,"required":true,"placeholder":"","show":false,"multiline":true,"value":"from typing import List\nfrom genflow.interface.custom.custom_component import CustomComponent\nfrom langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\nfrom langchain.schema import Document\n\n\nclass AzureAIDocumentIntelligenceLoaderComponent(CustomComponent):\n    display_name: str = \"AzureAIDocumentIntelligenceLoader\"\n    description: str = \"Azure ai document intelligence Loader.\"\n    documentation: str = \"https://docs.aiplanet.com/components/document-loaders#azureai-document-intelligence-loader\"\n\n    def build_config(self):\n        return {\n            \"file_path\": {\n                \"display_name\": \"File Path\",\n                \"required\": True,\n                \"field_type\": \"file\",\n                \"file_types\": [\"pdf\", \"jpeg\", \"png\", \"bmp\", \"tiff\"],\n                \"suffixes\": [\n                    \".pdf\",\n                    \".jpg\",\n                    \".jpeg\",\n                    \".png\",\n                    \".bmp\",\n                    \".dib\" \".tiff\",\n                    \".tif\",\n                ],\n                \"input_types\": [\"Input\"],\n            },\n            \"endpoint\": {\"display_name\": \"Endpoint\", \"required\": True},\n            \"key\": {\"display_name\": \"Key\", \"required\": True, \"password\": True},\n            \"api_model\": {\n                \"display_name\": \"API Model\",\n                \"required\": True,\n                \"value\": \"prebuilt-layout\",\n            },\n            \"code\": {\"show\": False},\n            \"file_size\": {\n                \"display_name\": \"File Size\",\n                \"required\": True,\n                \"advanced\": True,\n                \"field_type\": \"int\",\n                \"value\": 20,\n            },\n        }\n\n    def build(\n        self, file_path: str, endpoint: str, key: str, api_model: str, file_size: int\n    ) -> List[Document]:\n        loader = AzureAIDocumentIntelligenceLoader(\n            api_endpoint=endpoint, api_key=key, file_path=file_path, api_model=api_model\n        )\n        results = loader.load()\n        return results\n","password":false,"name":"code","advanced":false,"type":"code","list":false},"_type":"CustomComponent","api_model":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"prebuilt-layout","password":false,"name":"api_model","display_name":"API Model","advanced":false,"dynamic":false,"info":"","type":"str","list":false},"endpoint":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"endpoint","display_name":"Endpoint","advanced":false,"dynamic":false,"info":"","type":"str","list":false,"value":"https://fullstackai.cognitiveservices.azure.com/"},"file_path":{"required":true,"placeholder":"","show":true,"multiline":false,"suffixes":[".pdf",".jpg",".jpeg",".png",".bmp",".dib.tiff",".tif"],"password":false,"name":"file_path","display_name":"File Path","advanced":false,"input_types":["Input"],"dynamic":false,"info":"","type":"file","list":false,"fileTypes":["pdf","jpeg","png","bmp","tiff"],"file_path":"/mnt/models/files/d42d109e-2cf4-4280-84d2-2dd82a2456ff/7992fa1651259e0e89346e0cc65a5b8bea632589efa1af3c4b52875b27826410.png","value":"ai.png"},"file_size":{"required":true,"placeholder":"","show":true,"multiline":false,"value":20,"password":false,"name":"file_size","display_name":"File Size","advanced":true,"dynamic":false,"info":"","type":"int","list":false},"key":{"required":true,"placeholder":"","show":true,"multiline":false,"password":true,"name":"key","display_name":"Key","advanced":false,"dynamic":false,"info":"","type":"str","list":false,"value":""}},"description":"Azure ai document intelligence Loader.","base_classes":["Document"],"display_name":"AzureAIDocumentIntelligenceLoader","custom_fields":{"api_model":null,"endpoint":null,"file_path":null,"file_size":null,"key":null},"output_types":["AzureAIDocumentIntelligenceLoader"],"documentation":"https://docs.aiplanet.com/components/document-loaders#azureai-document-intelligence-loader","beta":true,"error":null},"id":"AzureAIDocumentIntelligenceLoader-VUrhj"},"positionAbsolute":{"x":249,"y":202.265625},"selected":true,"dragging":false},{"width":384,"height":501,"id":"RecursiveCharacterTextSplitter-Ku008","type":"genericNode","position":{"x":771.105649062728,"y":458.7525810390156},"data":{"type":"RecursiveCharacterTextSplitter","node":{"template":{"code":{"dynamic":true,"required":true,"placeholder":"","show":false,"multiline":true,"value":"from typing import Optional\nfrom genflow import CustomComponent\nfrom langchain.schema import Document\nfrom genflow.utils.util import build_loader_repr_from_documents\n\n\nclass RecursiveCharacterTextSplitterComponent(CustomComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text into chunks of a specified length.\"\n    documentation: str = \"https://docs.aiplanet.com/components/text-splitters#recursivecharactertextsplitter\"\n    \n    def build_config(self):\n        return {\n            \"documents\": {\n                \"display_name\": \"Documents\",\n                \"info\": \"The documents to split.\",\n            },\n            \"separators\": {\n                \"display_name\": \"Separators\",\n                \"info\": 'The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\n                \"display_name\": \"Chunk Size\",\n                \"info\": \"The maximum length of each chunk.\",\n                \"field_type\": \"int\",\n                \"value\": 1000,\n            },\n            \"chunk_overlap\": {\n                \"display_name\": \"Chunk Overlap\",\n                \"info\": \"The amount of overlap between chunks.\",\n                \"field_type\": \"int\",\n                \"value\": 200,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        documents: list[Document],\n        separators: Optional[list[str]] = None,\n        chunk_size: Optional[int] = 1000,\n        chunk_overlap: Optional[int] = 200,\n    ) -> list[Document]:\n        \"\"\"\n        Split text into chunks of a specified length.\n\n        Args:\n            separators (list[str]): The characters to split on.\n            chunk_size (int): The maximum length of each chunk.\n            chunk_overlap (int): The amount of overlap between chunks.\n            length_function (function): The function to use to calculate the length of the text.\n\n        Returns:\n            list[str]: The chunks of text.\n        \"\"\"\n        from langchain.text_splitter import RecursiveCharacterTextSplitter\n\n        if separators == \"\":\n            separators = None\n        elif separators:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [x.encode().decode(\"unicode-escape\") for x in separators]\n\n        # Make sure chunk_size and chunk_overlap are ints\n        if isinstance(chunk_size, str):\n            chunk_size = int(chunk_size)\n        if isinstance(chunk_overlap, str):\n            chunk_overlap = int(chunk_overlap)\n        splitter = RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=chunk_size,\n            chunk_overlap=chunk_overlap,\n        )\n\n        docs = splitter.split_documents(documents)\n        self.repr_value = build_loader_repr_from_documents(docs)\n        return docs\n","password":false,"name":"code","advanced":false,"type":"code","list":false},"_type":"CustomComponent","chunk_overlap":{"required":false,"placeholder":"","show":true,"multiline":false,"value":200,"password":false,"name":"chunk_overlap","display_name":"Chunk Overlap","advanced":false,"dynamic":false,"info":"The amount of overlap between chunks.","type":"int","list":false},"chunk_size":{"required":false,"placeholder":"","show":true,"multiline":false,"value":1000,"password":false,"name":"chunk_size","display_name":"Chunk Size","advanced":false,"dynamic":false,"info":"The maximum length of each chunk.","type":"int","list":false},"documents":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"documents","display_name":"Documents","advanced":false,"dynamic":false,"info":"The documents to split.","type":"Document","list":true},"separators":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"separators","display_name":"Separators","advanced":false,"dynamic":false,"info":"The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].","type":"str","list":true}},"description":"Split text into chunks of a specified length.","base_classes":["Document"],"display_name":"Recursive Character Text Splitter","custom_fields":{"chunk_overlap":null,"chunk_size":null,"documents":null,"separators":null},"output_types":["RecursiveCharacterTextSplitter"],"documentation":"https://docs.aiplanet.com/components/text-splitters#recursivecharactertextsplitter","beta":true,"error":null},"id":"RecursiveCharacterTextSplitter-Ku008"},"positionAbsolute":{"x":771.105649062728,"y":458.7525810390156},"selected":false},{"width":384,"height":469,"id":"PromptTemplate-D0wKQ","type":"genericNode","position":{"x":1254.9690248287286,"y":657.2606326353235},"data":{"type":"PromptTemplate","node":{"template":{"output_parser":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"output_parser","advanced":false,"dynamic":true,"info":"","type":"BaseOutputParser","list":false},"input_types":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"input_types","advanced":false,"dynamic":true,"info":"","type":"dict","list":false},"input_variables":{"required":true,"placeholder":"","show":false,"multiline":false,"password":false,"name":"input_variables","advanced":false,"dynamic":true,"info":"","type":"str","list":true,"value":["context","query"]},"partial_variables":{"required":false,"placeholder":"","show":false,"multiline":false,"password":false,"name":"partial_variables","advanced":false,"dynamic":true,"info":"","type":"dict","list":false},"template":{"required":true,"placeholder":"","show":true,"multiline":true,"password":false,"name":"template","advanced":false,"dynamic":true,"info":"","type":"prompt","list":false,"value":"You are an Image OCR agent, that describes and answer questions based on the given user query. You will be provided with the CONTEXT. Based on the CONTEXT answer the user query with truthfulness and honesty\n\nCONTEXT: {context}\nQUERY: {query}"},"template_format":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"f-string","password":false,"name":"template_format","advanced":false,"dynamic":true,"info":"","type":"str","list":false},"validate_template":{"required":false,"placeholder":"","show":false,"multiline":false,"value":false,"password":false,"name":"validate_template","advanced":false,"dynamic":true,"info":"","type":"bool","list":false},"_type":"PromptTemplate","context":{"required":false,"placeholder":"","show":true,"multiline":true,"value":"","password":false,"name":"context","display_name":"context","advanced":false,"input_types":["Document","BaseOutputParser","Input"],"dynamic":false,"info":"","type":"str","list":false},"query":{"required":false,"placeholder":"","show":true,"multiline":true,"value":"","password":false,"name":"query","display_name":"query","advanced":false,"input_types":["Document","BaseOutputParser","Input"],"dynamic":false,"info":"","type":"str","list":false}},"description":"A prompt template for a language model.","base_classes":["StringPromptTemplate","BasePromptTemplate","PromptTemplate"],"name":"","display_name":"PromptTemplate","documentation":"https://docs.aiplanet.com/components/prompts#prompt-template","custom_fields":{"":["context","query"],"template":["context","query"]},"output_types":[],"field_formatters":{},"beta":false,"error":null},"id":"PromptTemplate-D0wKQ"},"selected":false,"positionAbsolute":{"x":1254.9690248287286,"y":657.2606326353235},"dragging":false},{"width":384,"height":339,"id":"LLMChain-MgiAV","type":"genericNode","position":{"x":1842.5979730200725,"y":349.34757532968683},"data":{"type":"LLMChain","node":{"template":{"code":{"dynamic":true,"required":true,"placeholder":"","show":false,"multiline":true,"value":"from genflow import CustomComponent\nfrom langchain.chains import LLMChain\nfrom typing import Optional, Union, Callable\nfrom genflow.field_typing import (\n    BasePromptTemplate,\n    BaseLanguageModel,\n    BaseMemory,\n    Chain,\n)\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n    documentation: str = \"https://docs.aiplanet.com/components/chains#llm-chain\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: BasePromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Chain:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n","password":false,"name":"code","advanced":false,"type":"code","list":false},"_type":"CustomComponent","llm":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"llm","display_name":"LLM","advanced":false,"dynamic":false,"info":"","type":"BaseLanguageModel","list":false},"memory":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"memory","display_name":"Memory","advanced":false,"dynamic":false,"info":"","type":"BaseMemory","list":false},"prompt":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"prompt","display_name":"Prompt","advanced":false,"dynamic":false,"info":"","type":"BasePromptTemplate","list":false}},"description":"Chain to run queries against LLMs","base_classes":["Chain"],"display_name":"LLMChain","custom_fields":{"llm":null,"memory":null,"prompt":null},"output_types":["LLMChain"],"documentation":"https://docs.aiplanet.com/components/chains#llm-chain","beta":true,"error":null},"id":"LLMChain-MgiAV"},"selected":false,"positionAbsolute":{"x":1842.5979730200725,"y":349.34757532968683},"dragging":false},{"width":384,"height":577,"id":"ConversationBufferMemory-Lt3tY","type":"genericNode","position":{"x":1213.2372185272322,"y":5.34214500653934},"data":{"type":"ConversationBufferMemory","node":{"template":{"chat_memory":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"chat_memory","advanced":false,"dynamic":false,"info":"","type":"BaseChatMessageHistory","list":false},"ai_prefix":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"AI","password":false,"name":"ai_prefix","advanced":false,"dynamic":false,"info":"","type":"str","list":false},"human_prefix":{"required":false,"placeholder":"","show":false,"multiline":false,"value":"Human","password":false,"name":"human_prefix","advanced":false,"dynamic":false,"info":"","type":"str","list":false},"input_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"","password":false,"name":"input_key","advanced":false,"dynamic":false,"info":"The variable to be used as Chat Input when more than one variable is available.","type":"str","list":false},"memory_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"chat_history","password":false,"name":"memory_key","advanced":false,"dynamic":false,"info":"","type":"str","list":false},"output_key":{"required":false,"placeholder":"","show":true,"multiline":false,"value":"","password":false,"name":"output_key","advanced":false,"dynamic":false,"info":"The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)","type":"str","list":false},"return_messages":{"required":false,"placeholder":"","show":true,"multiline":false,"password":false,"name":"return_messages","advanced":false,"dynamic":false,"info":"","type":"bool","list":false},"_type":"ConversationBufferMemory"},"description":"Buffer for storing conversation memory.","base_classes":["BaseChatMemory","BaseMemory","ConversationBufferMemory"],"display_name":"ConversationBufferMemory","custom_fields":{},"output_types":[],"documentation":"https://docs.aiplanet.com/components/memories#conversationbuffermemory","beta":false,"error":null},"id":"ConversationBufferMemory-Lt3tY"},"selected":false,"positionAbsolute":{"x":1213.2372185272322,"y":5.34214500653934},"dragging":false},{"width":384,"height":735,"id":"AzureChatOpenAI-PrSmt","type":"genericNode","position":{"x":1229.8097186716457,"y":-788.0258182413977},"data":{"type":"AzureChatOpenAI","node":{"template":{"code":{"dynamic":true,"required":true,"placeholder":"","show":false,"multiline":true,"value":"from typing import Optional\nfrom genflow.interface.custom import CustomComponent\nfrom langchain.llms.base import BaseLLM\nfrom langchain.chat_models import AzureChatOpenAI\n\n\nclass AzureChatOpenAILLM(CustomComponent):\n    display_name: str = \"AzureChatOpenAI\"\n    description: str = \"Azure Chat Open AI Chat&Completion large language models.\"\n\n    AZURE_OPENAI_MODELS = [\n        \"gpt-4\",\n        \"gpt-4-32k\",\n        \"gpt-4-vision\",\n    ]\n\n    def build_config(self):\n        return {\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"gpt-4\",\n                \"options\": self.AZURE_OPENAI_MODELS,\n                \"required\": True,\n            },\n            \"api_key\": {\n                \"display_name\": \"AzureChatOpenAI API Key\",\n                \"required\": True,\n                \"password\": True,\n            },\n            \"api_base\": {\n                \"display_name\": \"AzureChatOpenAI API Base\",\n                \"required\": True,\n            },\n            \"api_type\": {\"display_name\": \"AzureChatOpenAI API Type\", \"required\": True},\n            \"azure_deployment\": {\n                \"display_name\": \"Deployment Name\",\n                \"required\": True,\n            },\n            \"api_version\": {\n                \"display_name\": \"API Version\",\n                \"value\": \"2023-07-01-preview\",\n                \"required\": True,\n                \"advanced\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"value\": 0.5,\n                \"field_type\": \"float\",\n                \"required\": False,\n            },\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"value\": 512,\n                \"required\": False,\n                \"field_type\": \"int\",\n                \"advanced\": True,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        model: str,\n        api_base: str,\n        api_type: str,\n        api_key: str,\n        azure_deployment: str,\n        api_version: str = \"2023-05-15\",\n        temperature: Optional[float] = 0.7,\n        max_tokens: Optional[int] = 512,\n    ) -> BaseLLM:\n        try:\n            output = AzureChatOpenAI(\n                model_name=model,\n                openai_api_base=api_base,\n                openai_api_type=api_type,\n                openai_api_key=api_key,\n                openai_api_version=api_version,\n                deployment_name=azure_deployment,\n                temperature=temperature,\n                max_tokens=max_tokens,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Azure ChatOpenAI model.\") from e\n        return output\n","password":false,"name":"code","advanced":false,"type":"code","list":false},"_type":"CustomComponent","api_base":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"api_base","display_name":"AzureChatOpenAI API Base","advanced":false,"dynamic":false,"info":"","type":"str","list":false,"value":"https://gpt-res.openai.azure.com/"},"api_key":{"required":true,"placeholder":"","show":true,"multiline":false,"password":true,"name":"api_key","display_name":"AzureChatOpenAI API Key","advanced":false,"dynamic":false,"info":"","type":"str","list":false,"value":""},"api_type":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"api_type","display_name":"AzureChatOpenAI API Type","advanced":false,"dynamic":false,"info":"","type":"str","list":false,"value":"azure"},"api_version":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"2023-07-01-preview","password":false,"name":"api_version","display_name":"API Version","advanced":true,"dynamic":false,"info":"","type":"str","list":false},"azure_deployment":{"required":true,"placeholder":"","show":true,"multiline":false,"password":false,"name":"azure_deployment","display_name":"Deployment Name","advanced":false,"dynamic":false,"info":"","type":"str","list":false,"value":"gpt4-inference"},"max_tokens":{"required":false,"placeholder":"","show":true,"multiline":false,"value":512,"password":false,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"","type":"int","list":false},"model":{"required":true,"placeholder":"","show":true,"multiline":false,"value":"gpt-4","password":false,"options":["gpt-4","gpt-4-32k","gpt-4-vision"],"name":"model","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","type":"str","list":true},"temperature":{"required":false,"placeholder":"","show":true,"multiline":false,"value":0.5,"password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","type":"float","list":false}},"description":"Azure Chat Open AI Chat&Completion large language models.","base_classes":["BaseLanguageModel","BaseLLM"],"display_name":"AzureChatOpenAI","custom_fields":{"api_base":null,"api_key":null,"api_type":null,"api_version":null,"azure_deployment":null,"max_tokens":null,"model":null,"temperature":null},"output_types":["AzureChatOpenAI"],"documentation":"","beta":true,"error":null},"id":"AzureChatOpenAI-PrSmt"},"selected":false,"positionAbsolute":{"x":1229.8097186716457,"y":-788.0258182413977},"dragging":false}],"edges":[{"source":"AzureAIDocumentIntelligenceLoader-VUrhj","sourceHandle":"{œbaseClassesœ:[œDocumentœ],œdataTypeœ:œAzureAIDocumentIntelligenceLoaderœ,œidœ:œAzureAIDocumentIntelligenceLoader-VUrhjœ}","target":"RecursiveCharacterTextSplitter-Ku008","targetHandle":"{œfieldNameœ:œdocumentsœ,œidœ:œRecursiveCharacterTextSplitter-Ku008œ,œinputTypesœ:null,œtypeœ:œDocumentœ}","data":{"targetHandle":{"fieldName":"documents","id":"RecursiveCharacterTextSplitter-Ku008","inputTypes":null,"type":"Document"},"sourceHandle":{"baseClasses":["Document"],"dataType":"AzureAIDocumentIntelligenceLoader","id":"AzureAIDocumentIntelligenceLoader-VUrhj"}},"style":{"stroke":"#555"},"className":"stroke-foreground  stroke-connection","animated":false,"id":"reactflow__edge-AzureAIDocumentIntelligenceLoader-VUrhj{œbaseClassesœ:[œDocumentœ],œdataTypeœ:œAzureAIDocumentIntelligenceLoaderœ,œidœ:œAzureAIDocumentIntelligenceLoader-VUrhjœ}-RecursiveCharacterTextSplitter-Ku008{œfieldNameœ:œdocumentsœ,œidœ:œRecursiveCharacterTextSplitter-Ku008œ,œinputTypesœ:null,œtypeœ:œDocumentœ}"},{"source":"RecursiveCharacterTextSplitter-Ku008","sourceHandle":"{œbaseClassesœ:[œDocumentœ],œdataTypeœ:œRecursiveCharacterTextSplitterœ,œidœ:œRecursiveCharacterTextSplitter-Ku008œ}","target":"PromptTemplate-D0wKQ","targetHandle":"{œfieldNameœ:œcontextœ,œidœ:œPromptTemplate-D0wKQœ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ,œInputœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"context","id":"PromptTemplate-D0wKQ","inputTypes":["Document","BaseOutputParser","Input"],"type":"str"},"sourceHandle":{"baseClasses":["Document"],"dataType":"RecursiveCharacterTextSplitter","id":"RecursiveCharacterTextSplitter-Ku008"}},"style":{"stroke":"#555"},"className":"stroke-foreground  stroke-connection","animated":false,"id":"reactflow__edge-RecursiveCharacterTextSplitter-Ku008{œbaseClassesœ:[œDocumentœ],œdataTypeœ:œRecursiveCharacterTextSplitterœ,œidœ:œRecursiveCharacterTextSplitter-Ku008œ}-PromptTemplate-D0wKQ{œfieldNameœ:œcontextœ,œidœ:œPromptTemplate-D0wKQœ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ,œInputœ],œtypeœ:œstrœ}"},{"source":"PromptTemplate-D0wKQ","sourceHandle":"{œbaseClassesœ:[œStringPromptTemplateœ,œBasePromptTemplateœ,œPromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-D0wKQœ}","target":"LLMChain-MgiAV","targetHandle":"{œfieldNameœ:œpromptœ,œidœ:œLLMChain-MgiAVœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}","data":{"targetHandle":{"fieldName":"prompt","id":"LLMChain-MgiAV","inputTypes":null,"type":"BasePromptTemplate"},"sourceHandle":{"baseClasses":["StringPromptTemplate","BasePromptTemplate","PromptTemplate"],"dataType":"PromptTemplate","id":"PromptTemplate-D0wKQ"}},"style":{"stroke":"#555"},"className":"stroke-foreground  stroke-connection","animated":false,"id":"reactflow__edge-PromptTemplate-D0wKQ{œbaseClassesœ:[œStringPromptTemplateœ,œBasePromptTemplateœ,œPromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-D0wKQœ}-LLMChain-MgiAV{œfieldNameœ:œpromptœ,œidœ:œLLMChain-MgiAVœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}"},{"source":"ConversationBufferMemory-Lt3tY","sourceHandle":"{œbaseClassesœ:[œBaseChatMemoryœ,œBaseMemoryœ,œConversationBufferMemoryœ],œdataTypeœ:œConversationBufferMemoryœ,œidœ:œConversationBufferMemory-Lt3tYœ}","target":"LLMChain-MgiAV","targetHandle":"{œfieldNameœ:œmemoryœ,œidœ:œLLMChain-MgiAVœ,œinputTypesœ:null,œtypeœ:œBaseMemoryœ}","data":{"targetHandle":{"fieldName":"memory","id":"LLMChain-MgiAV","inputTypes":null,"type":"BaseMemory"},"sourceHandle":{"baseClasses":["BaseChatMemory","BaseMemory","ConversationBufferMemory"],"dataType":"ConversationBufferMemory","id":"ConversationBufferMemory-Lt3tY"}},"style":{"stroke":"#555"},"className":"stroke-foreground  stroke-connection","animated":false,"id":"reactflow__edge-ConversationBufferMemory-Lt3tY{œbaseClassesœ:[œBaseChatMemoryœ,œBaseMemoryœ,œConversationBufferMemoryœ],œdataTypeœ:œConversationBufferMemoryœ,œidœ:œConversationBufferMemory-Lt3tYœ}-LLMChain-MgiAV{œfieldNameœ:œmemoryœ,œidœ:œLLMChain-MgiAVœ,œinputTypesœ:null,œtypeœ:œBaseMemoryœ}"},{"source":"AzureChatOpenAI-PrSmt","sourceHandle":"{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œAzureChatOpenAIœ,œidœ:œAzureChatOpenAI-PrSmtœ}","target":"LLMChain-MgiAV","targetHandle":"{œfieldNameœ:œllmœ,œidœ:œLLMChain-MgiAVœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}","data":{"targetHandle":{"fieldName":"llm","id":"LLMChain-MgiAV","inputTypes":null,"type":"BaseLanguageModel"},"sourceHandle":{"baseClasses":["BaseLanguageModel","BaseLLM"],"dataType":"AzureChatOpenAI","id":"AzureChatOpenAI-PrSmt"}},"style":{"stroke":"#555"},"className":"stroke-foreground  stroke-connection","animated":false,"id":"reactflow__edge-AzureChatOpenAI-PrSmt{œbaseClassesœ:[œBaseLanguageModelœ,œBaseLLMœ],œdataTypeœ:œAzureChatOpenAIœ,œidœ:œAzureChatOpenAI-PrSmtœ}-LLMChain-MgiAV{œfieldNameœ:œllmœ,œidœ:œLLMChain-MgiAVœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"}],"viewport":{"x":-191.64943137464388,"y":342.78677687237234,"zoom":0.7057814839869446}},"description":"Chat with the text on your image","name":"Image OCR chat","flow_type":"chat"}