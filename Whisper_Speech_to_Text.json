{
  "id": "08ca082c-3bd7-4db0-aa63-6f79a22f575d",
  "data": {
    "nodes": [
      {
        "width": 384,
        "height": 501,
        "id": "RecursiveCharacterTextSplitter-vfMTH",
        "type": "genericNode",
        "position": {
          "x": 715.1591932077537,
          "y": 0.764544979573671
        },
        "data": {
          "type": "RecursiveCharacterTextSplitter",
          "node": {
            "template": {
              "code": {
                "dynamic": true,
                "required": true,
                "placeholder": "",
                "show": false,
                "multiline": true,
                "value": "from typing import Optional\nfrom genflow import CustomComponent\nfrom langchain.schema import Document\nfrom genflow.utils.util import build_loader_repr_from_documents\n\n\nclass RecursiveCharacterTextSplitterComponent(CustomComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text into chunks of a specified length.\"\n    documentation: str = \"https://docs.aiplanet.com/components/text-splitters#recursivecharactertextsplitter\"\n    \n    def build_config(self):\n        return {\n            \"documents\": {\n                \"display_name\": \"Documents\",\n                \"info\": \"The documents to split.\",\n            },\n            \"separators\": {\n                \"display_name\": \"Separators\",\n                \"info\": 'The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n                \"is_list\": True,\n            },\n            \"chunk_size\": {\n                \"display_name\": \"Chunk Size\",\n                \"info\": \"The maximum length of each chunk.\",\n                \"field_type\": \"int\",\n                \"value\": 1000,\n            },\n            \"chunk_overlap\": {\n                \"display_name\": \"Chunk Overlap\",\n                \"info\": \"The amount of overlap between chunks.\",\n                \"field_type\": \"int\",\n                \"value\": 200,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        documents: list[Document],\n        separators: Optional[list[str]] = None,\n        chunk_size: Optional[int] = 1000,\n        chunk_overlap: Optional[int] = 200,\n    ) -> list[Document]:\n        \"\"\"\n        Split text into chunks of a specified length.\n\n        Args:\n            separators (list[str]): The characters to split on.\n            chunk_size (int): The maximum length of each chunk.\n            chunk_overlap (int): The amount of overlap between chunks.\n            length_function (function): The function to use to calculate the length of the text.\n\n        Returns:\n            list[str]: The chunks of text.\n        \"\"\"\n        from langchain.text_splitter import RecursiveCharacterTextSplitter\n\n        if separators == \"\":\n            separators = None\n        elif separators:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [x.encode().decode(\"unicode-escape\") for x in separators]\n\n        # Make sure chunk_size and chunk_overlap are ints\n        if isinstance(chunk_size, str):\n            chunk_size = int(chunk_size)\n        if isinstance(chunk_overlap, str):\n            chunk_overlap = int(chunk_overlap)\n        splitter = RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=chunk_size,\n            chunk_overlap=chunk_overlap,\n        )\n\n        docs = splitter.split_documents(documents)\n        self.repr_value = build_loader_repr_from_documents(docs)\n        return docs\n",
                "password": false,
                "name": "code",
                "advanced": false,
                "type": "code",
                "list": false
              },
              "_type": "CustomComponent",
              "chunk_overlap": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": 200,
                "password": false,
                "name": "chunk_overlap",
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "The amount of overlap between chunks.",
                "type": "int",
                "list": false
              },
              "chunk_size": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": 1000,
                "password": false,
                "name": "chunk_size",
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum length of each chunk.",
                "type": "int",
                "list": false
              },
              "documents": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "documents",
                "display_name": "Documents",
                "advanced": false,
                "dynamic": false,
                "info": "The documents to split.",
                "type": "Document",
                "list": true
              },
              "separators": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "separators",
                "display_name": "Separators",
                "advanced": false,
                "dynamic": false,
                "info": "The characters to split on.\nIf left empty defaults to [\"\\n\\n\", \"\\n\", \" \", \"\"].",
                "type": "str",
                "list": true
              }
            },
            "description": "Split text into chunks of a specified length.",
            "base_classes": [
              "Document"
            ],
            "display_name": "Recursive Character Text Splitter",
            "custom_fields": {
              "chunk_overlap": null,
              "chunk_size": null,
              "documents": null,
              "separators": null
            },
            "output_types": [
              "RecursiveCharacterTextSplitter"
            ],
            "documentation": "https://docs.aiplanet.com/components/text-splitters#recursivecharactertextsplitter",
            "beta": true,
            "error": null
          },
          "id": "RecursiveCharacterTextSplitter-vfMTH"
        },
        "positionAbsolute": {
          "x": 715.1591932077537,
          "y": 0.764544979573671
        },
        "selected": false,
        "dragging": false
      },
      {
        "width": 384,
        "height": 735,
        "id": "AzureChatOpenAI-W4KxI",
        "type": "genericNode",
        "position": {
          "x": 1608.665462080407,
          "y": -681.0252314723016
        },
        "data": {
          "type": "AzureChatOpenAI",
          "node": {
            "template": {
              "code": {
                "dynamic": true,
                "required": true,
                "placeholder": "",
                "show": false,
                "multiline": true,
                "value": "from typing import Optional\nfrom genflow.interface.custom import CustomComponent\nfrom langchain.llms.base import BaseLLM\nfrom langchain.chat_models import AzureChatOpenAI\n\n\nclass AzureChatOpenAILLM(CustomComponent):\n    display_name: str = \"AzureChatOpenAI\"\n    description: str = \"Azure Chat Open AI Chat&Completion large language models.\"\n    documentation: str = \"https://docs.aiplanet.com/components/large-language-models#azurechatopenai\"\n    \n    AZURE_OPENAI_MODELS = [\n        \"gpt-4\",\n        \"gpt-4-32k\",\n        \"gpt-4-vision\",\n    ]\n\n    def build_config(self):\n        return {\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"gpt-4\",\n                \"options\": self.AZURE_OPENAI_MODELS,\n                \"required\": True,\n            },\n            \"api_key\": {\n                \"display_name\": \"AzureChatOpenAI API Key\",\n                \"required\": True,\n                \"password\": True,\n            },\n            \"api_base\": {\n                \"display_name\": \"AzureChatOpenAI API Base\",\n                \"required\": True,\n            },\n            \"api_type\": {\"display_name\": \"AzureChatOpenAI API Type\", \"required\": True},\n            \"azure_deployment\": {\n                \"display_name\": \"Deployment Name\",\n                \"required\": True,\n            },\n            \"api_version\": {\n                \"display_name\": \"API Version\",\n                \"value\": \"2023-07-01-preview\",\n                \"required\": True,\n                \"advanced\": True,\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"value\": 0.5,\n                \"field_type\": \"float\",\n                \"required\": False,\n            },\n            \"max_tokens\": {\n                \"display_name\": \"Max Tokens\",\n                \"value\": 512,\n                \"required\": False,\n                \"field_type\": \"int\",\n                \"advanced\": True,\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        model: str,\n        api_base: str,\n        api_type: str,\n        api_key: str,\n        azure_deployment: str,\n        api_version: str = \"2023-05-15\",\n        temperature: Optional[float] = 0.7,\n        max_tokens: Optional[int] = 512,\n    ) -> BaseLLM:\n        try:\n            output = AzureChatOpenAI(\n                model_name=model,\n                openai_api_base=api_base,\n                openai_api_type=api_type,\n                openai_api_key=api_key,\n                openai_api_version=api_version,\n                deployment_name=azure_deployment,\n                temperature=temperature,\n                max_tokens=max_tokens,\n            )\n        except Exception as e:\n            raise ValueError(\"Could not connect to Azure ChatOpenAI model.\") from e\n        return output\n",
                "password": false,
                "name": "code",
                "advanced": false,
                "type": "code",
                "list": false
              },
              "_type": "CustomComponent",
              "api_base": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "api_base",
                "display_name": "AzureChatOpenAI API Base",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false,
                "value": ""
              },
              "api_key": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": true,
                "name": "api_key",
                "display_name": "AzureChatOpenAI API Key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false,
                "value": ""
              },
              "api_type": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "api_type",
                "display_name": "AzureChatOpenAI API Type",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false,
                "value": ""
              },
              "api_version": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "2023-07-01-preview",
                "password": false,
                "name": "api_version",
                "display_name": "API Version",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "azure_deployment": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "azure_deployment",
                "display_name": "Deployment Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false,
                "value": ""
              },
              "max_tokens": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": 512,
                "password": false,
                "name": "max_tokens",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "int",
                "list": false
              },
              "model": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "gpt-4-32k",
                "password": false,
                "options": [
                  "gpt-4",
                  "gpt-4-32k",
                  "gpt-4-vision"
                ],
                "name": "model",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": true
              },
              "temperature": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "0.1",
                "password": false,
                "name": "temperature",
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "float",
                "list": false
              }
            },
            "description": "Azure Chat Open AI Chat&Completion large language models.",
            "base_classes": [
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "display_name": "AzureChatOpenAI",
            "custom_fields": {
              "api_base": null,
              "api_key": null,
              "api_type": null,
              "api_version": null,
              "azure_deployment": null,
              "max_tokens": null,
              "model": null,
              "temperature": null
            },
            "output_types": [
              "AzureChatOpenAI"
            ],
            "documentation": "https://docs.aiplanet.com/components/large-language-models#azurechatopenai",
            "beta": true,
            "error": null
          },
          "id": "AzureChatOpenAI-W4KxI"
        },
        "selected": false,
        "positionAbsolute": {
          "x": 1608.665462080407,
          "y": -681.0252314723016
        },
        "dragging": false
      },
      {
        "width": 384,
        "height": 291,
        "id": "Chroma-MSsd9",
        "type": "genericNode",
        "position": {
          "x": 1430.3803245394756,
          "y": 827.7544464822664
        },
        "data": {
          "type": "Chroma",
          "node": {
            "template": {
              "code": {
                "dynamic": true,
                "required": true,
                "placeholder": "",
                "show": false,
                "multiline": true,
                "value": "from typing import Optional, Union\nfrom genflow import CustomComponent\n\nfrom langchain.vectorstores.chroma import Chroma\nfrom langchain.schema import Document\nfrom langchain.vectorstores.base import VectorStore\nfrom langchain.schema import BaseRetriever\nfrom langchain.embeddings.base import Embeddings\nimport chromadb  # type: ignore\n\n\nclass ChromaComponent(CustomComponent):\n    \"\"\"\n    A custom component for implementing a Vector Store using Chroma.\n    \"\"\"\n\n    display_name: str = \"Chroma\"\n    description: str = \"Implementation of Vector Store using Chroma\"\n    documentation = \"https://docs.aiplanet.com/components/vector-store#chroma\"\n    beta: bool = True\n\n    def build_config(self):\n        \"\"\"\n        Builds the configuration for the component.\n\n        Returns:\n        - dict: A dictionary containing the configuration options for the component.\n        \"\"\"\n        return {\n            \"collection_name\": {\n                \"display_name\": \"Collection Name\",\n                \"value\": \"genflow\",\n                \"required\": False,\n                \"advanced\": True,\n            },\n            \"persist\": {\n                \"display_name\": \"Persist\",\n                \"value\": True,\n                \"required\": False,\n                \"advanced\": True,\n            },\n            \"persist_directory\": {\n                \"display_name\": \"Persist Directory\",\n                \"value\": \"/mnt/models/chroma\",\n                \"required\": False,\n                \"advanced\": True,\n            },\n            \"code\": {\"show\": False, \"display_name\": \"Code\"},\n            \"documents\": {\"display_name\": \"Documents\", \"is_list\": True},\n            \"embedding\": {\"display_name\": \"Embedding\"},\n            \"chroma_server_cors_allow_origins\": {\n                \"display_name\": \"Server CORS Allow Origins\",\n                \"advanced\": True,\n            },\n            \"chroma_server_host\": {\"display_name\": \"Server Host\", \"advanced\": True},\n            \"chroma_server_port\": {\"display_name\": \"Server Port\", \"advanced\": True},\n            \"chroma_server_grpc_port\": {\n                \"display_name\": \"Server gRPC Port\",\n                \"advanced\": True,\n            },\n            \"chroma_server_ssl_enabled\": {\n                \"display_name\": \"Server SSL Enabled\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        chroma_server_ssl_enabled: bool,\n        collection_name: Optional[str] = \"genflow\",\n        persist: Optional[bool] = True,\n        persist_directory: Optional[str] = \"/mnt/models/chroma\",\n        embedding: Optional[Embeddings] = None,\n        documents: Optional[Document] = None,\n        chroma_server_cors_allow_origins: Optional[str] = None,\n        chroma_server_host: Optional[str] = None,\n        chroma_server_port: Optional[int] = None,\n        chroma_server_grpc_port: Optional[int] = None,\n    ) -> Union[VectorStore, BaseRetriever]:\n        \"\"\"\n        Builds the Vector Store or BaseRetriever object.\n\n        Args:\n        - collection_name (str): The name of the collection.\n        - persist_directory (Optional[str]): The directory to persist the Vector Store to.\n        - chroma_server_ssl_enabled (bool): Whether to enable SSL for the Chroma server.\n        - persist (bool): Whether to persist the Vector Store or not.\n        - embedding (Optional[Embeddings]): The embeddings to use for the Vector Store.\n        - documents (Optional[Document]): The documents to use for the Vector Store.\n        - chroma_server_cors_allow_origins (Optional[str]): The CORS allow origins for the Chroma server.\n        - chroma_server_host (Optional[str]): The host for the Chroma server.\n        - chroma_server_port (Optional[int]): The port for the Chroma server.\n        - chroma_server_grpc_port (Optional[int]): The gRPC port for the Chroma server.\n\n        Returns:\n        - Union[VectorStore, BaseRetriever]: The Vector Store or BaseRetriever object.\n        \"\"\"\n\n        # Chroma settings\n        chroma_settings = None\n\n        if chroma_server_host is not None:\n            chroma_settings = chromadb.config.Settings(\n                chroma_server_cors_allow_origins=chroma_server_cors_allow_origins\n                or None,\n                chroma_server_host=chroma_server_host,\n                chroma_server_port=chroma_server_port or None,\n                chroma_server_grpc_port=chroma_server_grpc_port or None,\n                chroma_server_ssl_enabled=chroma_server_ssl_enabled,\n            )\n\n        # If documents, then we need to create a Chroma instance using .from_documents\n        if documents is not None and embedding is not None:\n            return Chroma.from_documents(\n                documents=documents,  # type: ignore\n                persist_directory=persist_directory if persist else None,\n                collection_name=collection_name,\n                embedding=embedding,\n                client_settings=chroma_settings,\n            )\n\n        if embedding is not None:\n            return Chroma(\n                persist_directory=persist_directory,\n                client_settings=chroma_settings,\n                embedding_function=embedding,\n                collection_name=collection_name,\n            )\n\n        return Chroma(\n            persist_directory=persist_directory, client_settings=chroma_settings\n        )\n",
                "password": false,
                "name": "code",
                "advanced": false,
                "type": "code",
                "list": false
              },
              "_type": "CustomComponent",
              "chroma_server_cors_allow_origins": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "chroma_server_cors_allow_origins",
                "display_name": "Server CORS Allow Origins",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "chroma_server_grpc_port": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "chroma_server_grpc_port",
                "display_name": "Server gRPC Port",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "int",
                "list": false
              },
              "chroma_server_host": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "chroma_server_host",
                "display_name": "Server Host",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "chroma_server_port": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "chroma_server_port",
                "display_name": "Server Port",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "int",
                "list": false
              },
              "chroma_server_ssl_enabled": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": false,
                "password": false,
                "name": "chroma_server_ssl_enabled",
                "display_name": "Server SSL Enabled",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "bool",
                "list": false
              },
              "collection_name": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "genflow",
                "password": false,
                "name": "collection_name",
                "display_name": "Collection Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "documents": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "documents",
                "display_name": "Documents",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "Document",
                "list": true
              },
              "embedding": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "embedding",
                "display_name": "Embedding",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "Embeddings",
                "list": false
              },
              "persist": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": true,
                "password": false,
                "name": "persist",
                "display_name": "Persist",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "bool",
                "list": false
              },
              "persist_directory": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "/mnt/models/chroma",
                "password": false,
                "name": "persist_directory",
                "display_name": "Persist Directory",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              }
            },
            "description": "Implementation of Vector Store using Chroma",
            "base_classes": [
              "VectorStore",
              "BaseRetriever"
            ],
            "display_name": "Chroma",
            "custom_fields": {
              "chroma_server_cors_allow_origins": null,
              "chroma_server_grpc_port": null,
              "chroma_server_host": null,
              "chroma_server_port": null,
              "chroma_server_ssl_enabled": null,
              "collection_name": null,
              "documents": null,
              "embedding": null,
              "persist": null,
              "persist_directory": null
            },
            "output_types": [
              "Chroma"
            ],
            "documentation": "https://docs.aiplanet.com/components/vector-store#chroma",
            "beta": true,
            "error": null
          },
          "id": "Chroma-MSsd9"
        },
        "selected": false,
        "positionAbsolute": {
          "x": 1430.3803245394756,
          "y": 827.7544464822664
        },
        "dragging": false
      },
      {
        "width": 384,
        "height": 387,
        "id": "HuggingFaceEmbeddingInferenceAPI-USZgM",
        "type": "genericNode",
        "position": {
          "x": 701.3217227112808,
          "y": -598.0857498885518
        },
        "data": {
          "type": "HuggingFaceEmbeddingInferenceAPI",
          "node": {
            "template": {
              "code": {
                "dynamic": true,
                "required": true,
                "placeholder": "",
                "show": false,
                "multiline": true,
                "value": "from genflow import CustomComponent\nfrom langchain.embeddings.base import Embeddings\nfrom langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n\n\nclass HuggingFaceInferenceAPIEmbeddingsComponent(CustomComponent):\n    display_name: str = \"HuggingFaceInferenceAPI Embeddings\"\n    description: str = \"\"\"Access HuggingFaceEmbedding model via inference api,download models locally.\"\"\"\n    documentation: str = \"https://docs.aiplanet.com/components/embeddings#huggingface-inference-api-embeddings\"\n    beta = False\n\n    def build_config(self):\n        return {\n            \"inference_api_key\": {\n                \"display_name\": \"Inference API Key\",\n                \"is_list\": False,\n                \"required\": True,\n                \"value\": \"\",\n            },\n            \"model_name\": {\n                \"display_name\": \"Model Name\",\n                \"is_list\": False,\n                \"required\": True,\n                \"value\": \"\",\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(self, inference_api_key: str, model_name: str) -> Embeddings:\n        return HuggingFaceInferenceAPIEmbeddings(\n            api_key=inference_api_key, model_name=model_name\n        )\n",
                "password": false,
                "name": "code",
                "advanced": false,
                "type": "code",
                "list": false
              },
              "_type": "CustomComponent",
              "inference_api_key": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "",
                "password": false,
                "name": "inference_api_key",
                "display_name": "Inference API Key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "model_name": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "BAAI/bge-large-en-v1.5",
                "password": false,
                "name": "model_name",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              }
            },
            "description": "Access HuggingFaceEmbedding model via inference api,download models locally.",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "HuggingFaceInferenceAPI Embeddings",
            "custom_fields": {
              "inference_api_key": null,
              "model_name": null
            },
            "output_types": [
              "HuggingFaceEmbeddingInferenceAPI"
            ],
            "documentation": "https://docs.aiplanet.com/components/embeddings#huggingface-inference-api-embeddings",
            "beta": false,
            "error": null
          },
          "id": "HuggingFaceEmbeddingInferenceAPI-USZgM"
        },
        "selected": false,
        "positionAbsolute": {
          "x": 701.3217227112808,
          "y": -598.0857498885518
        },
        "dragging": false
      },
      {
        "width": 384,
        "height": 469,
        "id": "CustomComponent-N37VV",
        "type": "genericNode",
        "position": {
          "x": -26.27771861343183,
          "y": -70.17469282079313
        },
        "data": {
          "type": "CustomComponent",
          "node": {
            "template": {
              "code": {
                "dynamic": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": true,
                "value": "from genflow import CustomComponent\nfrom typing import Optional, List, Dict, Union\nfrom openai import OpenAI\nfrom langchain.schema import Document\nfrom langchain.docstore.document import Document\n\nclass Component(CustomComponent):\n    display_name: str = \"Whisper Transcriber\"\n    description: str = \"Converts audio to text using OpenAI's Whisper.\"\n\n    def build_config(self):\n        return {\"audio\":\n            {\"field_type\":\"file\",\n            \"suffixes\":[\".mp3\", \".mp4\"],\"input_types\":[\"Input\"]},\n            \"OpenAIKey\":\n                {\"field_type\":\"str\",\"password\":True,\"input_types\":[\"Input\"]}\n        }\n\n    def build(self, audio:str, OpenAIKey:str) -> List[Document]:\n        client = OpenAI(api_key=OpenAIKey)\n        \n        audio_file= open(audio, \"rb\")\n        transcript = client.audio.transcriptions.create(\n          model=\"whisper-1\", \n          file=audio_file,\n          response_format=\"text\"\n        )\n        \n        self.status = transcript\n        doc =  Document(page_content=transcript, metadata={\"source\": \"audio\"})\n        return doc",
                "password": false,
                "name": "code",
                "advanced": false,
                "type": "code",
                "list": false
              },
              "_type": "CustomComponent",
              "OpenAIKey": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": true,
                "name": "OpenAIKey",
                "display_name": "OpenAIKey",
                "advanced": false,
                "input_types": [
                  "Input"
                ],
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false,
                "value": ""
              },
              "audio": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "suffixes": [
                  ".mp3",
                  ".mp4"
                ],
                "password": false,
                "name": "audio",
                "display_name": "audio",
                "advanced": false,
                "input_types": [
                  "Input"
                ],
                "dynamic": false,
                "info": "",
                "type": "file",
                "list": false,
                "file_path": "/mnt/models/files/837a52da-ca1d-471e-aa8a-385b804ed470/2749b44e3cfd3c70eea9097cf2e97d91d07a6ce6b44fca9e71bdd1c3317106ba.mp3",
                "value": ""
              }
            },
            "description": "Converts audio to text using OpenAI's Whisper.",
            "base_classes": [
              "Document"
            ],
            "display_name": "Whisper Transcriber",
            "custom_fields": {
              "OpenAIKey": null,
              "audio": null
            },
            "output_types": [
              "Document"
            ],
            "documentation": "",
            "beta": true,
            "error": null
          },
          "id": "CustomComponent-N37VV"
        },
        "selected": false,
        "positionAbsolute": {
          "x": -26.27771861343183,
          "y": -70.17469282079313
        },
        "dragging": false
      },
      {
        "width": 384,
        "height": 457,
        "id": "Input-V4esj",
        "type": "genericNode",
        "position": {
          "x": -702.320697451038,
          "y": 14.33095181856649
        },
        "data": {
          "type": "Input",
          "node": {
            "template": {
              "input_value": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": true,
                "value": "",
                "password": false,
                "name": "input_value",
                "display_name": "Input Value",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "file",
                "list": false,
                "file_path": null
              },
              "input_key": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "File ",
                "password": false,
                "name": "input_key",
                "display_name": "Input Key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "input_type": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "File",
                "password": false,
                "options": [
                  "File",
                  "Url",
                  "Text"
                ],
                "name": "input_type",
                "display_name": "Input Type",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "_type": "Input"
            },
            "description": "Input is used to specify the type of input.",
            "base_classes": [
              "Input"
            ],
            "display_name": "Input",
            "custom_fields": {},
            "output_types": [
              "Input"
            ],
            "documentation": "https://docs.aiplanet.com/components/inputs",
            "beta": false,
            "error": null
          },
          "id": "Input-V4esj"
        },
        "selected": false,
        "positionAbsolute": {
          "x": -702.320697451038,
          "y": 14.33095181856649
        },
        "dragging": false
      },
      {
        "width": 384,
        "height": 529,
        "id": "ConversationBufferMemory-Bbv66",
        "type": "genericNode",
        "position": {
          "x": 1801.2704708238798,
          "y": 230.17579978325892
        },
        "data": {
          "type": "ConversationBufferMemory",
          "node": {
            "template": {
              "code": {
                "dynamic": true,
                "required": true,
                "placeholder": "",
                "show": false,
                "multiline": true,
                "value": "from typing import Optional, Union\nfrom langchain.memory.chat_memory import BaseMemory, BaseChatMemory\nfrom langchain.memory.buffer import ConversationBufferMemory\nfrom langchain.memory.chat_message_histories.postgres import PostgresChatMessageHistory\n\nfrom genflow import CustomComponent\n\n\nclass ConversationBufferMemoryComponent(CustomComponent):\n    display_name: str = \"ConversationBufferMemory\"\n    description: str = \"Buffer for storing conversation memory.\"\n    documentation: str = (\n        \"https://docs.aiplanet.com/components/memories#conversationbuffermemory\"\n    )\n    beta = False\n\n    def build_config(self):\n        return {\n            \"input_key\": {\n                \"display_name\": \"Input Key\",\n                \"required\": False,\n                \"value\": \"\",\n                \"info\": \"The variable to be used as Chat Input when more than one variable is available.\",\n            },\n            \"memory_key\": {\n                \"display_name\": \"Memory Key\",\n                \"required\": False,\n                \"value\": \"history\",\n            },\n            \"output_key\": {\n                \"display_name\": \"Output Key\",\n                \"required\": False,\n                \"value\": \"\",\n                \"info\": \"The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)\",\n            },\n            \"return_messages\": {\n                \"display_name\": \"Return Messages\",\n                \"field_type\": \"bool\",\n                \"required\": False,\n                \"value\": True,\n            },\n            \"session_id\": {\n                \"display_name\": \"Session ID\",\n                \"required\": False,\n                \"advanced\": True,\n                \"value\": \"genflow_memory_db\",\n            },\n            \"connection_string\": {\n                \"display_name\": \"Connection String\",\n                \"required\": False,\n                \"advanced\": True,\n                \"value\": \"\",\n            },\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        input_key: Optional[str] = \"\",\n        memory_key: Optional[str] = \"history\",\n        output_key: Optional[str] = \"\",\n        return_messages: Optional[bool] = True,\n        session_id: Optional[str] = \"genflow_memory_db\",\n        connection_string: Optional[str] = \"\",\n    ) -> Union[BaseMemory, BaseChatMemory]:\n        chat_memory = PostgresChatMessageHistory(\n            session_id=session_id, connection_string=connection_string\n        )\n\n        keys = {}\n\n        if input_key and input_key != \"\":\n            keys[\"input_key\"] = input_key\n\n        if output_key and output_key != \"\":\n            keys[\"output_key\"] = output_key\n\n        return ConversationBufferMemory(\n            chat_memory=chat_memory,\n            memory_key=memory_key,\n            return_messages=return_messages,\n            **keys\n        )\n",
                "password": false,
                "name": "code",
                "advanced": false,
                "type": "code",
                "list": false
              },
              "_type": "CustomComponent",
              "connection_string": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "",
                "password": false,
                "name": "connection_string",
                "display_name": "Connection String",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "input_key": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "question",
                "password": false,
                "name": "input_key",
                "display_name": "Input Key",
                "advanced": false,
                "dynamic": false,
                "info": "The variable to be used as Chat Input when more than one variable is available.",
                "type": "str",
                "list": false
              },
              "memory_key": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "chat_history",
                "password": false,
                "name": "memory_key",
                "display_name": "Memory Key",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              },
              "output_key": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "answer",
                "password": false,
                "name": "output_key",
                "display_name": "Output Key",
                "advanced": false,
                "dynamic": false,
                "info": "The variable to be used as Chat Output (e.g. answer in a ConversationalRetrievalChain)",
                "type": "str",
                "list": false
              },
              "return_messages": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": true,
                "password": false,
                "name": "return_messages",
                "display_name": "Return Messages",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "bool",
                "list": false
              },
              "session_id": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "genflow_memory_db",
                "password": false,
                "name": "session_id",
                "display_name": "Session ID",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": false
              }
            },
            "description": "Buffer for storing conversation memory.",
            "base_classes": [
              "BaseMemory",
              "BaseChatMemory",
              "BaseMemory"
            ],
            "display_name": "ConversationBufferMemory",
            "custom_fields": {
              "connection_string": null,
              "input_key": null,
              "memory_key": null,
              "output_key": null,
              "return_messages": null,
              "session_id": null
            },
            "output_types": [
              "ConversationBufferMemory"
            ],
            "documentation": "https://docs.aiplanet.com/components/memories#conversationbuffermemory",
            "beta": false,
            "error": null
          },
          "id": "ConversationBufferMemory-Bbv66"
        },
        "selected": false,
        "positionAbsolute": {
          "x": 1801.2704708238798,
          "y": 230.17579978325892
        },
        "dragging": false
      },
      {
        "width": 384,
        "height": 497,
        "id": "ConversationalRetrievalChain-x01sl",
        "type": "genericNode",
        "position": {
          "x": 2531.265923045576,
          "y": 243.75711052226725
        },
        "data": {
          "type": "ConversationalRetrievalChain",
          "node": {
            "template": {
              "code": {
                "dynamic": true,
                "required": true,
                "placeholder": "",
                "show": false,
                "multiline": true,
                "value": "from typing import Optional, Union, Callable\nfrom genflow import CustomComponent\nfrom genflow.field_typing import (\n    BasePromptTemplate,\n    BaseLanguageModel,\n    BaseMemory,\n    Chain,\n    BaseRetriever,\n)\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain.prompts import PromptTemplate\n\n\nclass ConversationalRetrievalChainComponent(CustomComponent):\n    \"\"\"\n    A custom component for implementing a RetrievalQA using Prompt.\n    \"\"\"\n\n    display_name: str = \"ConversationalRetrievalChain\"\n    description: str = \"Implementation of ConversationalRetrievalChain: allows Memory, Custom Prompt, Retriever\"\n    documentation: str = \"https://docs.aiplanet.com/components/chains#conversationalretrievalchain\"\n    beta: bool = True\n    \n    CHAIN_TYPE_OPTIONS = [\n        'stuff','map_reduce','refine','map_rerank'\n    ]\n\n    def build_config(self):\n        \"\"\"\n        Builds the configuration for the component.\n\n        Returns:\n        - dict: A dictionary containing the configuration options for the component.\n        \"\"\"\n        return {\n            \"chain_type\":{\"display\":\"chain_type\",\"value\":\"stuff\",\"options\":self.CHAIN_TYPE_OPTIONS,\"required\":True},\n            \"llm\":{\"display_name\":\"LLM\",\"required\":True},\n            \"prompt\":{\"display_name\":\"Prompt\"},\n            \"memory\":{\"display_name\":\"Memory\"},\n            \"retriever\":{\"display_name\":\"Retriever\",\"required\":True},\n            \"code\": {\"show\": False}, \n        }\n\n    def build(\n       self,\n       llm:BaseLanguageModel,\n       retriever: BaseRetriever,\n       prompt: Optional[BasePromptTemplate] = None,\n       chain_type:str = \"stuff\",\n       memory: BaseMemory = None,\n    ) -> Chain:\n        \"\"\"\n        Builds the RetrievalQA with prompt\n\n        Args:\n        - llm: Large Language Models\n        - chain_type: used to load a specific type of chain for question-answering\n        - chain_type_kwargs: chain keywords argument to pass prompt\n        - retriever: vector store to retrieve k relevant context information\n        - memory: memory to provide chat_history for object\n\n        Returns:\n        - Chain: The ConversationalRetrievalChain.from_llm\n        \"\"\"\n\n        DEFAULT_TEMPLATE = \"\"\"\n            Answer the question based on the chat history(delimited by <hs></hs>) and context(delimited by <ctx> </ctx>) below.\n            -----------\n            <ctx>\n            {context}\n            </ctx>\n            -----------\n            <hs>\n            {chat_history}\n            </hs>\n            -----------\n            Question: {question}\n            Answer:\n        \"\"\"\n\n        DEFAULT_PROMPT = PromptTemplate(\n                input_variables=[\"context\", \"question\", \"chat_history\"],\n                template=DEFAULT_TEMPLATE\n            )\n        \n        if prompt==None:\n            prompt = DEFAULT_PROMPT\n\n        return ConversationalRetrievalChain.from_llm(\n                            llm=llm,\n                            retriever=retriever.as_retriever(), chain_type=chain_type,return_source_documents=True,\n                            verbose = False,\n                            combine_docs_chain_kwargs={'prompt': prompt},\n                            memory = memory,\n                        )\n",
                "password": false,
                "name": "code",
                "advanced": false,
                "type": "code",
                "list": false
              },
              "_type": "CustomComponent",
              "chain_type": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "value": "stuff",
                "password": false,
                "options": [
                  "stuff",
                  "map_reduce",
                  "refine",
                  "map_rerank"
                ],
                "name": "chain_type",
                "display_name": "chain_type",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "str",
                "list": true
              },
              "llm": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "llm",
                "display_name": "LLM",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "BaseLanguageModel",
                "list": false
              },
              "memory": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "memory",
                "display_name": "Memory",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "BaseMemory",
                "list": false
              },
              "prompt": {
                "required": false,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "prompt",
                "display_name": "Prompt",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "BasePromptTemplate",
                "list": false
              },
              "retriever": {
                "required": true,
                "placeholder": "",
                "show": true,
                "multiline": false,
                "password": false,
                "name": "retriever",
                "display_name": "Retriever",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "type": "BaseRetriever",
                "list": false
              }
            },
            "description": "Implementation of ConversationalRetrievalChain: allows Memory, Custom Prompt, Retriever",
            "base_classes": [
              "Chain"
            ],
            "display_name": "ConversationalRetrievalChain",
            "custom_fields": {
              "chain_type": null,
              "llm": null,
              "memory": null,
              "prompt": null,
              "retriever": null
            },
            "output_types": [
              "ConversationalRetrievalChain"
            ],
            "documentation": "https://docs.aiplanet.com/components/chains#conversationalretrievalchain",
            "beta": true,
            "error": null
          },
          "id": "ConversationalRetrievalChain-x01sl"
        },
        "positionAbsolute": {
          "x": 2531.265923045576,
          "y": 243.75711052226725
        },
        "selected": false,
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "HuggingFaceEmbeddingInferenceAPI-USZgM",
        "sourceHandle": "{baseClasses:[Embeddings],dataType:HuggingFaceEmbeddingInferenceAPI,id:HuggingFaceEmbeddingInferenceAPI-USZgM}",
        "target": "Chroma-MSsd9",
        "targetHandle": "{fieldName:embedding,id:Chroma-MSsd9,inputTypes:null,type:Embeddings}",
        "data": {
          "targetHandle": {
            "fieldName": "embedding",
            "id": "Chroma-MSsd9",
            "inputTypes": null,
            "type": "Embeddings"
          },
          "sourceHandle": {
            "baseClasses": [
              "Embeddings"
            ],
            "dataType": "HuggingFaceEmbeddingInferenceAPI",
            "id": "HuggingFaceEmbeddingInferenceAPI-USZgM"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-HuggingFaceEmbeddingInferenceAPI-USZgM{baseClasses:[Embeddings],dataType:HuggingFaceEmbeddingInferenceAPI,id:HuggingFaceEmbeddingInferenceAPI-USZgM}-Chroma-MSsd9{fieldName:embedding,id:Chroma-MSsd9,inputTypes:null,type:Embeddings}"
      },
      {
        "source": "RecursiveCharacterTextSplitter-vfMTH",
        "sourceHandle": "{baseClasses:[Document],dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-vfMTH}",
        "target": "Chroma-MSsd9",
        "targetHandle": "{fieldName:documents,id:Chroma-MSsd9,inputTypes:null,type:Document}",
        "data": {
          "targetHandle": {
            "fieldName": "documents",
            "id": "Chroma-MSsd9",
            "inputTypes": null,
            "type": "Document"
          },
          "sourceHandle": {
            "baseClasses": [
              "Document"
            ],
            "dataType": "RecursiveCharacterTextSplitter",
            "id": "RecursiveCharacterTextSplitter-vfMTH"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-RecursiveCharacterTextSplitter-vfMTH{baseClasses:[Document],dataType:RecursiveCharacterTextSplitter,id:RecursiveCharacterTextSplitter-vfMTH}-Chroma-MSsd9{fieldName:documents,id:Chroma-MSsd9,inputTypes:null,type:Document}"
      },
      {
        "source": "CustomComponent-N37VV",
        "sourceHandle": "{baseClasses:[Document],dataType:CustomComponent,id:CustomComponent-N37VV}",
        "target": "RecursiveCharacterTextSplitter-vfMTH",
        "targetHandle": "{fieldName:documents,id:RecursiveCharacterTextSplitter-vfMTH,inputTypes:null,type:Document}",
        "data": {
          "targetHandle": {
            "fieldName": "documents",
            "id": "RecursiveCharacterTextSplitter-vfMTH",
            "inputTypes": null,
            "type": "Document"
          },
          "sourceHandle": {
            "baseClasses": [
              "Document"
            ],
            "dataType": "CustomComponent",
            "id": "CustomComponent-N37VV"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-CustomComponent-N37VV{baseClasses:[Document],dataType:CustomComponent,id:CustomComponent-N37VV}-RecursiveCharacterTextSplitter-vfMTH{fieldName:documents,id:RecursiveCharacterTextSplitter-vfMTH,inputTypes:null,type:Document}"
      },
      {
        "source": "Input-V4esj",
        "sourceHandle": "{baseClasses:[Input],dataType:Input,id:Input-V4esj}",
        "target": "CustomComponent-N37VV",
        "targetHandle": "{fieldName:audio,id:CustomComponent-N37VV,inputTypes:[Input],type:file}",
        "data": {
          "targetHandle": {
            "fieldName": "audio",
            "id": "CustomComponent-N37VV",
            "inputTypes": [
              "Input"
            ],
            "type": "file"
          },
          "sourceHandle": {
            "baseClasses": [
              "Input"
            ],
            "dataType": "Input",
            "id": "Input-V4esj"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-gray-900  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-Input-V4esj{baseClasses:[Input],dataType:Input,id:Input-V4esj}-CustomComponent-N37VV{fieldName:audio,id:CustomComponent-N37VV,inputTypes:[Input],type:file}"
      },
      {
        "source": "AzureChatOpenAI-W4KxI",
        "sourceHandle": "{baseClasses:[BaseLanguageModel,BaseLLM],dataType:AzureChatOpenAI,id:AzureChatOpenAI-W4KxI}",
        "target": "ConversationalRetrievalChain-x01sl",
        "targetHandle": "{fieldName:llm,id:ConversationalRetrievalChain-x01sl,inputTypes:null,type:BaseLanguageModel}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "ConversationalRetrievalChain-x01sl",
            "inputTypes": null,
            "type": "BaseLanguageModel"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseLanguageModel",
              "BaseLLM"
            ],
            "dataType": "AzureChatOpenAI",
            "id": "AzureChatOpenAI-W4KxI"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-AzureChatOpenAI-W4KxI{baseClasses:[BaseLanguageModel,BaseLLM],dataType:AzureChatOpenAI,id:AzureChatOpenAI-W4KxI}-ConversationalRetrievalChain-x01sl{fieldName:llm,id:ConversationalRetrievalChain-x01sl,inputTypes:null,type:BaseLanguageModel}"
      },
      {
        "source": "ConversationBufferMemory-Bbv66",
        "sourceHandle": "{baseClasses:[BaseMemory,BaseChatMemory,BaseMemory],dataType:ConversationBufferMemory,id:ConversationBufferMemory-Bbv66}",
        "target": "ConversationalRetrievalChain-x01sl",
        "targetHandle": "{fieldName:memory,id:ConversationalRetrievalChain-x01sl,inputTypes:null,type:BaseMemory}",
        "data": {
          "targetHandle": {
            "fieldName": "memory",
            "id": "ConversationalRetrievalChain-x01sl",
            "inputTypes": null,
            "type": "BaseMemory"
          },
          "sourceHandle": {
            "baseClasses": [
              "BaseMemory",
              "BaseChatMemory",
              "BaseMemory"
            ],
            "dataType": "ConversationBufferMemory",
            "id": "ConversationBufferMemory-Bbv66"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-ConversationBufferMemory-Bbv66{baseClasses:[BaseMemory,BaseChatMemory,BaseMemory],dataType:ConversationBufferMemory,id:ConversationBufferMemory-Bbv66}-ConversationalRetrievalChain-x01sl{fieldName:memory,id:ConversationalRetrievalChain-x01sl,inputTypes:null,type:BaseMemory}"
      },
      {
        "source": "Chroma-MSsd9",
        "sourceHandle": "{baseClasses:[VectorStore,BaseRetriever],dataType:Chroma,id:Chroma-MSsd9}",
        "target": "ConversationalRetrievalChain-x01sl",
        "targetHandle": "{fieldName:retriever,id:ConversationalRetrievalChain-x01sl,inputTypes:null,type:BaseRetriever}",
        "data": {
          "targetHandle": {
            "fieldName": "retriever",
            "id": "ConversationalRetrievalChain-x01sl",
            "inputTypes": null,
            "type": "BaseRetriever"
          },
          "sourceHandle": {
            "baseClasses": [
              "VectorStore",
              "BaseRetriever"
            ],
            "dataType": "Chroma",
            "id": "Chroma-MSsd9"
          }
        },
        "style": {
          "stroke": "#555"
        },
        "className": "stroke-foreground  stroke-connection",
        "animated": false,
        "id": "reactflow__edge-Chroma-MSsd9{baseClasses:[VectorStore,BaseRetriever],dataType:Chroma,id:Chroma-MSsd9}-ConversationalRetrievalChain-x01sl{fieldName:retriever,id:ConversationalRetrievalChain-x01sl,inputTypes:null,type:BaseRetriever}"
      }
    ],
    "viewport": {
      "x": 226.36200412635026,
      "y": 230.68077585358526,
      "zoom": 0.4151900698125826
    }
  },
  "description": "This stack allows you to extract text from an audio file and chat with the information present in it. You just have to put the Huggingface Access token and the Azure API key, deployment name, and URL for the LLM.",
  "name": "Whisper Speech to Text",
  "flow_type": "chat"
}